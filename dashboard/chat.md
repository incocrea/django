# Chat ‚Äî `/chat`

## Informaci√≥n General

La interfaz de Chat es el canal principal de comunicaci√≥n directa con Django. Permite mantener conversaciones en texto con el delegado digital, seleccionar el modo cognitivo que controla cu√°nta inteligencia y recursos usa Django para responder, y observar metadatos de cada respuesta (modelo usado, agentes involucrados, fuentes de conocimiento). Es la interfaz que desencadena el pipeline completo del orquestador ‚Äî cada mensaje enviado aqu√≠ activa los 10+ pasos de procesamiento, incluyendo clasificaci√≥n, decisi√≥n, planificaci√≥n, recall de memoria, generaci√≥n LLM, revisiones de identidad/gobernanza, evaluaci√≥n, y persistencia.

---

## Informaci√≥n Presentada

### Historial de Mensajes

√Årea de scroll vertical que muestra la conversaci√≥n actual como burbujas de mensaje alternadas:

- **Mensajes del usuario**: Alineados a la derecha, fondo acento
- **Mensajes de Django**: Alineados a la izquierda, fondo oscuro, con metadatos adicionales:
  - **Indicador multi-agente**: Badge que muestra si m√∫ltiples agentes colaboraron
  - **Modelo usado**: Nombre del provider y modelo (ej: "gemini-2.5-flash")
  - **Modo cognitivo activo**: Badge indicando el modo que gener√≥ la respuesta
  - **Fuentes de conocimiento**: Indicadores de qu√© tiers de memoria contribuyeron a la respuesta (working, episodic, semantic, procedural)

### Selector de Modo Cognitivo

Bot√≥n c√≠clico en la barra de input que rota entre 3 modos. El modo seleccionado se env√≠a como par√°metro `cognitive_mode` en cada petici√≥n `POST /chat`:

| Modo | Icono | Color | Comportamiento |
|------|-------|-------|----------------|
| **Full (1)** | üü¢ | Verde | Web search + LLM + todas las memorias. Sin restricciones. Usa habilidades como web-research si est√°n habilitadas. |
| **Memory+LLM (2)** | üü° | Amarillo | **Modo por defecto**. LLM genera pero solo basado en memoria recalled. Filtro sem√°ntico a `learned_knowledge`. Inyecta Knowledge Boundary + Status Header en el system prompt. Sin web. |
| **Memory Only (3)** | üî¥ | Rojo | Solo recall de memoria, **sin llamada LLM**. El orquestador ensambla l√≠neas `[tier/category] text` desde memorias recalled y retorna directamente. |

### Estado de Conexi√≥n

El header muestra el estado del WebSocket (conectado/desconectado) y el nombre del modelo activo.

### Persistencia

- Las conversaciones se persisten en `localStorage` v√≠a Zustand persist middleware
- NO hay persistencia server-side del historial de chat mostrado ‚Äî el backend guarda en Postgres si la DB est√° disponible, pero la UI solo lee desde localStorage
- Cada sesi√≥n del dashboard mantiene un `conversation_id` √∫nico

---

## Acciones

### 1. Enviar Mensaje
- **Tipo**: API Call
- **Comportamiento**: Llama `POST /chat` con `{message, conversation_id, cognitive_mode}`
- **Impacto en Django**: **Activa el pipeline completo del orquestador** (25+ pasos internos):
  1. Crea/reutiliza conversaci√≥n en Postgres
  2. Guarda mensaje del usuario en DB
  3. Emite `agent_state.thinking` v√≠a WebSocket
  4. Carga historial de conversaci√≥n (√∫ltimos 20 mensajes desde DB)
  5. Ejecuta pipeline: Classify ‚Üí Decision Engine ‚Üí Identity phases (6C, 6D, 7A, 8A, 8B) ‚Üí Planner ‚Üí Memory Recall + Mode Filter ‚Üí Identity phases (6A, 7B) ‚Üí Corrections ‚Üí Identity Context (6B) ‚Üí Prompt Build ‚Üí LLM Generate ‚Üí Identity Review ‚Üí Governance Review ‚Üí Memory Consolidation (7C) ‚Üí Memory Store + Evaluation (5 m√≥dulos) + Identity Enforcement (5A, 5B, 5C) + Persistence ‚Üí Health Monitor (9A) ‚Üí Health Regulation (9B) ‚Üí Evolution (10A) ‚Üí Shadow Sim (10B) ‚Üí Version Candidate (10C)
  6. Guarda respuesta en DB
  7. Emite `chat.response_generated` y `agent_state.idle`
  8. Retorna `ChatResponse` con contenido, metadata, y trace
- **Efectos colaterales**: Cada mensaje genera registros en ~10 tablas Postgres, actualiza memoria working + episodic, puede disparar evaluaciones de drift de identidad, y crea un cognitive trace completo.

### 2. Cambiar Modo Cognitivo
- **Tipo**: Estado local
- **Comportamiento**: Rota c√≠clicamente entre modo 1 ‚Üí 2 ‚Üí 3 ‚Üí 1
- **Impacto en Django**: Afecta el PR√ìXIMO mensaje. No llama ninguna API al cambiar ‚Äî el modo se incluye como par√°metro en la siguiente petici√≥n `POST /chat`, modificando fundamentalmente qu√© pasos del pipeline se ejecutan.

### 3. Limpiar Conversaci√≥n
- **Tipo**: Estado local √∫nicamente
- **Comportamiento**: Borra el historial de mensajes del localStorage y genera un nuevo `conversation_id`
- **Impacto en Django**: **Ninguno** ‚Äî no llama `POST /memory/working/clear` ni ning√∫n endpoint backend. Solo limpia la vista del cliente. La working memory del conversation_id anterior sigue existiendo en el servidor hasta que expire por TTL (1 hora) o alcance el l√≠mite de sesiones (50).

---

## Informaci√≥n T√©cnica

| Aspecto | Detalle |
|---------|---------|
| **Ruta** | `/chat` |
| **Archivos** | `dashboard/app/chat/page.tsx` (14 l√≠neas, wrapper), `dashboard/components/chat/chat-panel.tsx` (199 l√≠neas, l√≥gica principal), `dashboard/components/chat/message-bubble.tsx` (100 l√≠neas, renderizado de burbuja) |
| **L√≠neas totales** | ~313 l√≠neas |
| **APIs al cargar** | Ninguna ‚Äî restaura historial desde localStorage |
| **API por mensaje** | `POST /chat` con `{message, conversation_id, cognitive_mode}` |
| **Estado** | Zustand store con persistencia localStorage (`chat-storage` key) |
| **Respuesta esperada** | `ChatResponse { content, metadata: {model, provider, agents, trace_id}, cognitive_mode }` |
| **Iconos** | lucide-react: Send, Loader2, Brain, MessageSquare |

**√öltima actualizaci√≥n**: 2025-06-23
